# 下一步行动清单

## ✅ 你已经完成的工作
- ✓ 相机连接成功
- ✓ 机械臂连接成功  
- ✓ 机械手连接成功
- ✓ 相机内参已获取 (`camera_intrinsics.json`)

---

## 🎯 下一步需要完成的任务

### **第 1 步: 手眼标定** ⭐⭐⭐ (最重要，必须先完成)

**为什么需要**: 要将相机看到的物体位置转换到机器人基座坐标系，才能让机器人正确抓取

**需要的工具**:
- AprilTag 标定板 (75mm, tag25h9 family)
- 可以打印或购买: https://github.com/AprilRobotics/apriltag-imgs

**操作步骤**:
```bash
# 1. 将 AprilTag 固定在桌面上
# 2. 运行标定程序
python camera_calibreate.py

# 3. 按提示移动机械臂到不同位置 (15-20次)
#    - 每次按 'c' 保存
#    - 尽量覆盖不同角度和距离
#    - 确保 AprilTag 始终在相机视野内

# 4. 标定完成后验证
python vis_cam_to_base.py
# 看机械臂末端坐标轴是否正确投影到图像上
```

**预计时间**: 30-60 分钟

**输出**: `calibration_results/camera_calibration_XXXXXX.npz`

---

### **第 2 步: 点云获取和分割测试**

**为什么需要**: 需要从场景中分离出衣物的3D点云

**操作步骤**:
```bash
# 1. 测试基本点云生成
python get_pc.py
# 应该看到点云可视化窗口

# 2. 下载 SAM 模型权重 (用于分割)
wget https://dl.fbaipublicfiles.com/segment_anything/sam_vit_h_4b8939.pth

# 3. 安装 SAM
pip install segment-anything

# 4. 测试衣物分割
python get_garment_pointcloud.py
# 在弹出窗口中点击衣物区域，按空格确认
```

**预计时间**: 30 分钟

**输出**: `garment_pointcloud.ply` (衣物点云)

---

### **第 3 步: VLM 配置**

**为什么需要**: VLM 负责分析图像，生成折叠计划和关键点

**选项 1: 使用云端 API** (推荐初期测试)
```python
# 修改 vlm_motion_planning_main.py 中的配置
CONFIG = {
    "vlm_base_url": "https://api.openai.com/v1",  # OpenAI API
    "vlm_model_name": "gpt-4-vision-preview",
}

# 设置环境变量
export VLM_API_KEY="your-api-key"
```

**选项 2: 本地部署 VLM** (推荐长期使用)
```bash
# 使用 vLLM 部署 Qwen-VL (需要 GPU)
pip install vllm

python -m vllm.entrypoints.openai.api_server \
    --model Qwen/Qwen-VL-Chat \
    --port 8000

# 然后配置
CONFIG = {
    "vlm_base_url": "http://localhost:8000/v1",
    "vlm_model_name": "Qwen-VL-Chat",
}
```

**测试 VLM**:
```bash
python vlm_interface.py captured_color.png
# 应该返回 JSON 格式的 plan 和 points
```

**预计时间**: 1-2 小时 (取决于选择哪种方式)

---

### **第 4 步: 测试 2D→3D 投影**

**为什么需要**: 验证 VLM 输出的 2D 边界框能正确转换为 3D 抓取点

**操作步骤**:
```bash
# 1. 更新标定文件路径
# 编辑 bbox_to_3d.py，修改:
calib_file = "calibration_results/camera_calibration_YOUR_FILE.npz"

# 2. 运行测试
python bbox_to_3d.py
# 检查输出的 3D 坐标是否在工作空间内
```

**预计时间**: 20 分钟

---

### **第 5 步: 运动原语测试** ⚠️ (需要安全环境)

**为什么需要**: 在真实机器人上验证基本动作

**⚠️ 安全提示**:
- 清空机器人工作空间
- 准备好紧急停止按钮
- 第一次测试时降低速度

**操作步骤**:
```bash
# 创建测试脚本 (见指南中的 test_motion.py)
# 逐步测试:
# 1. move_to_home()
# 2. open_both_hands()
# 3. grasp_and_move() - 使用安全的测试坐标
```

**预计时间**: 1-2 小时 (包括调试和调整参数)

---

### **第 6 步: 运行完整流程** 🎬

**操作步骤**:
```bash
# 1. 更新所有配置 (见 VLM_MOTION_PLANNING_GUIDE.md)
# 编辑 vlm_motion_planning_main.py

# 2. 准备场景
# - 将衣物平铺在桌面上
# - 确保光照充足
# - 相机能完整看到衣物

# 3. 运行主程序
python vlm_motion_planning_main.py

# 4. 检查 debug_output/ 中的调试信息
```

**预计时间**: 初次运行 2-3 小时 (包括调试)

---

## 📋 需要更新的配置文件

在运行主程序前，需要更新以下配置:

### 1. `vlm_motion_planning_main.py`
```python
CONFIG = {
    "camera_sn": "YOUR_CAMERA_SN",           # 你的相机序列号
    "left_arm_ip": "192.168.100.100",        # 左臂IP
    "right_arm_ip": "192.168.100.101",       # 右臂IP
    "left_hand_port": "/dev/ttyUSB0",        # 左手端口
    "right_hand_port": "/dev/ttyUSB1",       # 右手端口
    
    "calib_file": "calibration_results/camera_calibration_YOUR_FILE.npz",  # 标定文件
    
    "vlm_base_url": "YOUR_VLM_ENDPOINT",     # VLM API地址
    "vlm_model_name": "YOUR_MODEL_NAME",     # 模型名称
}
```

### 2. `motion_primitives.py` (如果需要)
```python
# 调整 home 位置和抓取姿态
self.home_left = np.array([-0.6, 0.0, 0.5, 3.14, 0, 0])
self.home_right = np.array([0.6, 0.0, 0.5, 3.14, 0, 0])
```

---

## 📚 参考文档

1. **完整实施指南**: `VLM_MOTION_PLANNING_GUIDE.md`
2. **Isaac Sim 参考代码**: `/home/psibot/Downloads/Fold_Tops_HALO_mp.py`
3. **快速开始**: `快速开始.md`

---

## 🎯 推荐的实施顺序总结

```
第1步 (必须) → 手眼标定          [30-60分钟]
     ↓
第2步         → 点云分割测试      [30分钟]
     ↓
第3步         → VLM配置和测试     [1-2小时]
     ↓
第4步         → 2D→3D投影验证    [20分钟]
     ↓
第5步 (关键) → 运动原语测试      [1-2小时]
     ↓
第6步 (最终) → 完整流程运行      [2-3小时]
```

**总预计时间**: 6-10 小时 (分多次完成)

---

## ✨ 新增的代码文件

我已经为你创建了以下新文件:

1. ✅ `get_garment_pointcloud.py` - 衣物点云提取
2. ✅ `bbox_to_3d.py` - 2D→3D 投影
3. ✅ `vlm_interface.py` - VLM 接口
4. ✅ `motion_primitives.py` - 运动原语
5. ✅ `vlm_motion_planning_main.py` - 主程序
6. ✅ `VLM_MOTION_PLANNING_GUIDE.md` - 完整指南
7. ✅ `下一步行动清单.md` - 本文件

---

## 💡 重要提示

- **第1步 (手眼标定) 是最关键的**，必须先完成且质量要好
- **第5步 (运动测试) 需要格外注意安全**
- 每一步完成后建议保存结果，方便后续调试
- 遇到问题随时参考 `VLM_MOTION_PLANNING_GUIDE.md` 中的故障排查部分

---

**从第1步开始吧！祝你顺利！🚀**

